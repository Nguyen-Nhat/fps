// Code generated by ent, DO NOT EDIT.

package ent

import (
	"context"
	"errors"
	"fmt"
	"time"

	"entgo.io/ent/dialect/sql"
	"entgo.io/ent/dialect/sql/sqlgraph"
	"entgo.io/ent/schema/field"
	"git.teko.vn/loyalty-system/loyalty-file-processing/internal/ent/ent/predicate"
	"git.teko.vn/loyalty-system/loyalty-file-processing/internal/ent/ent/processingfilerow"
)

// ProcessingFileRowUpdate is the builder for updating ProcessingFileRow entities.
type ProcessingFileRowUpdate struct {
	config
	hooks    []Hook
	mutation *ProcessingFileRowMutation
}

// Where appends a list predicates to the ProcessingFileRowUpdate builder.
func (pfru *ProcessingFileRowUpdate) Where(ps ...predicate.ProcessingFileRow) *ProcessingFileRowUpdate {
	pfru.mutation.Where(ps...)
	return pfru
}

// SetFileID sets the "file_id" field.
func (pfru *ProcessingFileRowUpdate) SetFileID(i int64) *ProcessingFileRowUpdate {
	pfru.mutation.ResetFileID()
	pfru.mutation.SetFileID(i)
	return pfru
}

// AddFileID adds i to the "file_id" field.
func (pfru *ProcessingFileRowUpdate) AddFileID(i int64) *ProcessingFileRowUpdate {
	pfru.mutation.AddFileID(i)
	return pfru
}

// SetRowIndex sets the "row_index" field.
func (pfru *ProcessingFileRowUpdate) SetRowIndex(i int32) *ProcessingFileRowUpdate {
	pfru.mutation.ResetRowIndex()
	pfru.mutation.SetRowIndex(i)
	return pfru
}

// AddRowIndex adds i to the "row_index" field.
func (pfru *ProcessingFileRowUpdate) AddRowIndex(i int32) *ProcessingFileRowUpdate {
	pfru.mutation.AddRowIndex(i)
	return pfru
}

// SetRowDataRaw sets the "row_data_raw" field.
func (pfru *ProcessingFileRowUpdate) SetRowDataRaw(s string) *ProcessingFileRowUpdate {
	pfru.mutation.SetRowDataRaw(s)
	return pfru
}

// SetTaskIndex sets the "task_index" field.
func (pfru *ProcessingFileRowUpdate) SetTaskIndex(i int32) *ProcessingFileRowUpdate {
	pfru.mutation.ResetTaskIndex()
	pfru.mutation.SetTaskIndex(i)
	return pfru
}

// AddTaskIndex adds i to the "task_index" field.
func (pfru *ProcessingFileRowUpdate) AddTaskIndex(i int32) *ProcessingFileRowUpdate {
	pfru.mutation.AddTaskIndex(i)
	return pfru
}

// SetTaskMapping sets the "task_mapping" field.
func (pfru *ProcessingFileRowUpdate) SetTaskMapping(s string) *ProcessingFileRowUpdate {
	pfru.mutation.SetTaskMapping(s)
	return pfru
}

// SetTaskDependsOn sets the "task_depends_on" field.
func (pfru *ProcessingFileRowUpdate) SetTaskDependsOn(s string) *ProcessingFileRowUpdate {
	pfru.mutation.SetTaskDependsOn(s)
	return pfru
}

// SetTaskRequestRaw sets the "task_request_raw" field.
func (pfru *ProcessingFileRowUpdate) SetTaskRequestRaw(s string) *ProcessingFileRowUpdate {
	pfru.mutation.SetTaskRequestRaw(s)
	return pfru
}

// SetTaskResponseRaw sets the "task_response_raw" field.
func (pfru *ProcessingFileRowUpdate) SetTaskResponseRaw(s string) *ProcessingFileRowUpdate {
	pfru.mutation.SetTaskResponseRaw(s)
	return pfru
}

// SetStatus sets the "status" field.
func (pfru *ProcessingFileRowUpdate) SetStatus(i int16) *ProcessingFileRowUpdate {
	pfru.mutation.ResetStatus()
	pfru.mutation.SetStatus(i)
	return pfru
}

// AddStatus adds i to the "status" field.
func (pfru *ProcessingFileRowUpdate) AddStatus(i int16) *ProcessingFileRowUpdate {
	pfru.mutation.AddStatus(i)
	return pfru
}

// SetErrorDisplay sets the "error_display" field.
func (pfru *ProcessingFileRowUpdate) SetErrorDisplay(s string) *ProcessingFileRowUpdate {
	pfru.mutation.SetErrorDisplay(s)
	return pfru
}

// SetExecutedTime sets the "executed_time" field.
func (pfru *ProcessingFileRowUpdate) SetExecutedTime(i int64) *ProcessingFileRowUpdate {
	pfru.mutation.ResetExecutedTime()
	pfru.mutation.SetExecutedTime(i)
	return pfru
}

// AddExecutedTime adds i to the "executed_time" field.
func (pfru *ProcessingFileRowUpdate) AddExecutedTime(i int64) *ProcessingFileRowUpdate {
	pfru.mutation.AddExecutedTime(i)
	return pfru
}

// SetCreatedAt sets the "created_at" field.
func (pfru *ProcessingFileRowUpdate) SetCreatedAt(t time.Time) *ProcessingFileRowUpdate {
	pfru.mutation.SetCreatedAt(t)
	return pfru
}

// SetNillableCreatedAt sets the "created_at" field if the given value is not nil.
func (pfru *ProcessingFileRowUpdate) SetNillableCreatedAt(t *time.Time) *ProcessingFileRowUpdate {
	if t != nil {
		pfru.SetCreatedAt(*t)
	}
	return pfru
}

// SetUpdatedAt sets the "updated_at" field.
func (pfru *ProcessingFileRowUpdate) SetUpdatedAt(t time.Time) *ProcessingFileRowUpdate {
	pfru.mutation.SetUpdatedAt(t)
	return pfru
}

// Mutation returns the ProcessingFileRowMutation object of the builder.
func (pfru *ProcessingFileRowUpdate) Mutation() *ProcessingFileRowMutation {
	return pfru.mutation
}

// Save executes the query and returns the number of nodes affected by the update operation.
func (pfru *ProcessingFileRowUpdate) Save(ctx context.Context) (int, error) {
	var (
		err      error
		affected int
	)
	pfru.defaults()
	if len(pfru.hooks) == 0 {
		affected, err = pfru.sqlSave(ctx)
	} else {
		var mut Mutator = MutateFunc(func(ctx context.Context, m Mutation) (Value, error) {
			mutation, ok := m.(*ProcessingFileRowMutation)
			if !ok {
				return nil, fmt.Errorf("unexpected mutation type %T", m)
			}
			pfru.mutation = mutation
			affected, err = pfru.sqlSave(ctx)
			mutation.done = true
			return affected, err
		})
		for i := len(pfru.hooks) - 1; i >= 0; i-- {
			if pfru.hooks[i] == nil {
				return 0, fmt.Errorf("ent: uninitialized hook (forgotten import ent/runtime?)")
			}
			mut = pfru.hooks[i](mut)
		}
		if _, err := mut.Mutate(ctx, pfru.mutation); err != nil {
			return 0, err
		}
	}
	return affected, err
}

// SaveX is like Save, but panics if an error occurs.
func (pfru *ProcessingFileRowUpdate) SaveX(ctx context.Context) int {
	affected, err := pfru.Save(ctx)
	if err != nil {
		panic(err)
	}
	return affected
}

// Exec executes the query.
func (pfru *ProcessingFileRowUpdate) Exec(ctx context.Context) error {
	_, err := pfru.Save(ctx)
	return err
}

// ExecX is like Exec, but panics if an error occurs.
func (pfru *ProcessingFileRowUpdate) ExecX(ctx context.Context) {
	if err := pfru.Exec(ctx); err != nil {
		panic(err)
	}
}

// defaults sets the default values of the builder before save.
func (pfru *ProcessingFileRowUpdate) defaults() {
	if _, ok := pfru.mutation.UpdatedAt(); !ok {
		v := processingfilerow.UpdateDefaultUpdatedAt()
		pfru.mutation.SetUpdatedAt(v)
	}
}

func (pfru *ProcessingFileRowUpdate) sqlSave(ctx context.Context) (n int, err error) {
	_spec := &sqlgraph.UpdateSpec{
		Node: &sqlgraph.NodeSpec{
			Table:   processingfilerow.Table,
			Columns: processingfilerow.Columns,
			ID: &sqlgraph.FieldSpec{
				Type:   field.TypeInt,
				Column: processingfilerow.FieldID,
			},
		},
	}
	if ps := pfru.mutation.predicates; len(ps) > 0 {
		_spec.Predicate = func(selector *sql.Selector) {
			for i := range ps {
				ps[i](selector)
			}
		}
	}
	if value, ok := pfru.mutation.FileID(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeInt64,
			Value:  value,
			Column: processingfilerow.FieldFileID,
		})
	}
	if value, ok := pfru.mutation.AddedFileID(); ok {
		_spec.Fields.Add = append(_spec.Fields.Add, &sqlgraph.FieldSpec{
			Type:   field.TypeInt64,
			Value:  value,
			Column: processingfilerow.FieldFileID,
		})
	}
	if value, ok := pfru.mutation.RowIndex(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeInt32,
			Value:  value,
			Column: processingfilerow.FieldRowIndex,
		})
	}
	if value, ok := pfru.mutation.AddedRowIndex(); ok {
		_spec.Fields.Add = append(_spec.Fields.Add, &sqlgraph.FieldSpec{
			Type:   field.TypeInt32,
			Value:  value,
			Column: processingfilerow.FieldRowIndex,
		})
	}
	if value, ok := pfru.mutation.RowDataRaw(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  value,
			Column: processingfilerow.FieldRowDataRaw,
		})
	}
	if value, ok := pfru.mutation.TaskIndex(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeInt32,
			Value:  value,
			Column: processingfilerow.FieldTaskIndex,
		})
	}
	if value, ok := pfru.mutation.AddedTaskIndex(); ok {
		_spec.Fields.Add = append(_spec.Fields.Add, &sqlgraph.FieldSpec{
			Type:   field.TypeInt32,
			Value:  value,
			Column: processingfilerow.FieldTaskIndex,
		})
	}
	if value, ok := pfru.mutation.TaskMapping(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  value,
			Column: processingfilerow.FieldTaskMapping,
		})
	}
	if value, ok := pfru.mutation.TaskDependsOn(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  value,
			Column: processingfilerow.FieldTaskDependsOn,
		})
	}
	if value, ok := pfru.mutation.TaskRequestRaw(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  value,
			Column: processingfilerow.FieldTaskRequestRaw,
		})
	}
	if value, ok := pfru.mutation.TaskResponseRaw(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  value,
			Column: processingfilerow.FieldTaskResponseRaw,
		})
	}
	if value, ok := pfru.mutation.Status(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeInt16,
			Value:  value,
			Column: processingfilerow.FieldStatus,
		})
	}
	if value, ok := pfru.mutation.AddedStatus(); ok {
		_spec.Fields.Add = append(_spec.Fields.Add, &sqlgraph.FieldSpec{
			Type:   field.TypeInt16,
			Value:  value,
			Column: processingfilerow.FieldStatus,
		})
	}
	if value, ok := pfru.mutation.ErrorDisplay(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  value,
			Column: processingfilerow.FieldErrorDisplay,
		})
	}
	if value, ok := pfru.mutation.ExecutedTime(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeInt64,
			Value:  value,
			Column: processingfilerow.FieldExecutedTime,
		})
	}
	if value, ok := pfru.mutation.AddedExecutedTime(); ok {
		_spec.Fields.Add = append(_spec.Fields.Add, &sqlgraph.FieldSpec{
			Type:   field.TypeInt64,
			Value:  value,
			Column: processingfilerow.FieldExecutedTime,
		})
	}
	if value, ok := pfru.mutation.CreatedAt(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeTime,
			Value:  value,
			Column: processingfilerow.FieldCreatedAt,
		})
	}
	if value, ok := pfru.mutation.UpdatedAt(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeTime,
			Value:  value,
			Column: processingfilerow.FieldUpdatedAt,
		})
	}
	if n, err = sqlgraph.UpdateNodes(ctx, pfru.driver, _spec); err != nil {
		if _, ok := err.(*sqlgraph.NotFoundError); ok {
			err = &NotFoundError{processingfilerow.Label}
		} else if sqlgraph.IsConstraintError(err) {
			err = &ConstraintError{msg: err.Error(), wrap: err}
		}
		return 0, err
	}
	return n, nil
}

// ProcessingFileRowUpdateOne is the builder for updating a single ProcessingFileRow entity.
type ProcessingFileRowUpdateOne struct {
	config
	fields   []string
	hooks    []Hook
	mutation *ProcessingFileRowMutation
}

// SetFileID sets the "file_id" field.
func (pfruo *ProcessingFileRowUpdateOne) SetFileID(i int64) *ProcessingFileRowUpdateOne {
	pfruo.mutation.ResetFileID()
	pfruo.mutation.SetFileID(i)
	return pfruo
}

// AddFileID adds i to the "file_id" field.
func (pfruo *ProcessingFileRowUpdateOne) AddFileID(i int64) *ProcessingFileRowUpdateOne {
	pfruo.mutation.AddFileID(i)
	return pfruo
}

// SetRowIndex sets the "row_index" field.
func (pfruo *ProcessingFileRowUpdateOne) SetRowIndex(i int32) *ProcessingFileRowUpdateOne {
	pfruo.mutation.ResetRowIndex()
	pfruo.mutation.SetRowIndex(i)
	return pfruo
}

// AddRowIndex adds i to the "row_index" field.
func (pfruo *ProcessingFileRowUpdateOne) AddRowIndex(i int32) *ProcessingFileRowUpdateOne {
	pfruo.mutation.AddRowIndex(i)
	return pfruo
}

// SetRowDataRaw sets the "row_data_raw" field.
func (pfruo *ProcessingFileRowUpdateOne) SetRowDataRaw(s string) *ProcessingFileRowUpdateOne {
	pfruo.mutation.SetRowDataRaw(s)
	return pfruo
}

// SetTaskIndex sets the "task_index" field.
func (pfruo *ProcessingFileRowUpdateOne) SetTaskIndex(i int32) *ProcessingFileRowUpdateOne {
	pfruo.mutation.ResetTaskIndex()
	pfruo.mutation.SetTaskIndex(i)
	return pfruo
}

// AddTaskIndex adds i to the "task_index" field.
func (pfruo *ProcessingFileRowUpdateOne) AddTaskIndex(i int32) *ProcessingFileRowUpdateOne {
	pfruo.mutation.AddTaskIndex(i)
	return pfruo
}

// SetTaskMapping sets the "task_mapping" field.
func (pfruo *ProcessingFileRowUpdateOne) SetTaskMapping(s string) *ProcessingFileRowUpdateOne {
	pfruo.mutation.SetTaskMapping(s)
	return pfruo
}

// SetTaskDependsOn sets the "task_depends_on" field.
func (pfruo *ProcessingFileRowUpdateOne) SetTaskDependsOn(s string) *ProcessingFileRowUpdateOne {
	pfruo.mutation.SetTaskDependsOn(s)
	return pfruo
}

// SetTaskRequestRaw sets the "task_request_raw" field.
func (pfruo *ProcessingFileRowUpdateOne) SetTaskRequestRaw(s string) *ProcessingFileRowUpdateOne {
	pfruo.mutation.SetTaskRequestRaw(s)
	return pfruo
}

// SetTaskResponseRaw sets the "task_response_raw" field.
func (pfruo *ProcessingFileRowUpdateOne) SetTaskResponseRaw(s string) *ProcessingFileRowUpdateOne {
	pfruo.mutation.SetTaskResponseRaw(s)
	return pfruo
}

// SetStatus sets the "status" field.
func (pfruo *ProcessingFileRowUpdateOne) SetStatus(i int16) *ProcessingFileRowUpdateOne {
	pfruo.mutation.ResetStatus()
	pfruo.mutation.SetStatus(i)
	return pfruo
}

// AddStatus adds i to the "status" field.
func (pfruo *ProcessingFileRowUpdateOne) AddStatus(i int16) *ProcessingFileRowUpdateOne {
	pfruo.mutation.AddStatus(i)
	return pfruo
}

// SetErrorDisplay sets the "error_display" field.
func (pfruo *ProcessingFileRowUpdateOne) SetErrorDisplay(s string) *ProcessingFileRowUpdateOne {
	pfruo.mutation.SetErrorDisplay(s)
	return pfruo
}

// SetExecutedTime sets the "executed_time" field.
func (pfruo *ProcessingFileRowUpdateOne) SetExecutedTime(i int64) *ProcessingFileRowUpdateOne {
	pfruo.mutation.ResetExecutedTime()
	pfruo.mutation.SetExecutedTime(i)
	return pfruo
}

// AddExecutedTime adds i to the "executed_time" field.
func (pfruo *ProcessingFileRowUpdateOne) AddExecutedTime(i int64) *ProcessingFileRowUpdateOne {
	pfruo.mutation.AddExecutedTime(i)
	return pfruo
}

// SetCreatedAt sets the "created_at" field.
func (pfruo *ProcessingFileRowUpdateOne) SetCreatedAt(t time.Time) *ProcessingFileRowUpdateOne {
	pfruo.mutation.SetCreatedAt(t)
	return pfruo
}

// SetNillableCreatedAt sets the "created_at" field if the given value is not nil.
func (pfruo *ProcessingFileRowUpdateOne) SetNillableCreatedAt(t *time.Time) *ProcessingFileRowUpdateOne {
	if t != nil {
		pfruo.SetCreatedAt(*t)
	}
	return pfruo
}

// SetUpdatedAt sets the "updated_at" field.
func (pfruo *ProcessingFileRowUpdateOne) SetUpdatedAt(t time.Time) *ProcessingFileRowUpdateOne {
	pfruo.mutation.SetUpdatedAt(t)
	return pfruo
}

// Mutation returns the ProcessingFileRowMutation object of the builder.
func (pfruo *ProcessingFileRowUpdateOne) Mutation() *ProcessingFileRowMutation {
	return pfruo.mutation
}

// Select allows selecting one or more fields (columns) of the returned entity.
// The default is selecting all fields defined in the entity schema.
func (pfruo *ProcessingFileRowUpdateOne) Select(field string, fields ...string) *ProcessingFileRowUpdateOne {
	pfruo.fields = append([]string{field}, fields...)
	return pfruo
}

// Save executes the query and returns the updated ProcessingFileRow entity.
func (pfruo *ProcessingFileRowUpdateOne) Save(ctx context.Context) (*ProcessingFileRow, error) {
	var (
		err  error
		node *ProcessingFileRow
	)
	pfruo.defaults()
	if len(pfruo.hooks) == 0 {
		node, err = pfruo.sqlSave(ctx)
	} else {
		var mut Mutator = MutateFunc(func(ctx context.Context, m Mutation) (Value, error) {
			mutation, ok := m.(*ProcessingFileRowMutation)
			if !ok {
				return nil, fmt.Errorf("unexpected mutation type %T", m)
			}
			pfruo.mutation = mutation
			node, err = pfruo.sqlSave(ctx)
			mutation.done = true
			return node, err
		})
		for i := len(pfruo.hooks) - 1; i >= 0; i-- {
			if pfruo.hooks[i] == nil {
				return nil, fmt.Errorf("ent: uninitialized hook (forgotten import ent/runtime?)")
			}
			mut = pfruo.hooks[i](mut)
		}
		v, err := mut.Mutate(ctx, pfruo.mutation)
		if err != nil {
			return nil, err
		}
		nv, ok := v.(*ProcessingFileRow)
		if !ok {
			return nil, fmt.Errorf("unexpected node type %T returned from ProcessingFileRowMutation", v)
		}
		node = nv
	}
	return node, err
}

// SaveX is like Save, but panics if an error occurs.
func (pfruo *ProcessingFileRowUpdateOne) SaveX(ctx context.Context) *ProcessingFileRow {
	node, err := pfruo.Save(ctx)
	if err != nil {
		panic(err)
	}
	return node
}

// Exec executes the query on the entity.
func (pfruo *ProcessingFileRowUpdateOne) Exec(ctx context.Context) error {
	_, err := pfruo.Save(ctx)
	return err
}

// ExecX is like Exec, but panics if an error occurs.
func (pfruo *ProcessingFileRowUpdateOne) ExecX(ctx context.Context) {
	if err := pfruo.Exec(ctx); err != nil {
		panic(err)
	}
}

// defaults sets the default values of the builder before save.
func (pfruo *ProcessingFileRowUpdateOne) defaults() {
	if _, ok := pfruo.mutation.UpdatedAt(); !ok {
		v := processingfilerow.UpdateDefaultUpdatedAt()
		pfruo.mutation.SetUpdatedAt(v)
	}
}

func (pfruo *ProcessingFileRowUpdateOne) sqlSave(ctx context.Context) (_node *ProcessingFileRow, err error) {
	_spec := &sqlgraph.UpdateSpec{
		Node: &sqlgraph.NodeSpec{
			Table:   processingfilerow.Table,
			Columns: processingfilerow.Columns,
			ID: &sqlgraph.FieldSpec{
				Type:   field.TypeInt,
				Column: processingfilerow.FieldID,
			},
		},
	}
	id, ok := pfruo.mutation.ID()
	if !ok {
		return nil, &ValidationError{Name: "id", err: errors.New(`ent: missing "ProcessingFileRow.id" for update`)}
	}
	_spec.Node.ID.Value = id
	if fields := pfruo.fields; len(fields) > 0 {
		_spec.Node.Columns = make([]string, 0, len(fields))
		_spec.Node.Columns = append(_spec.Node.Columns, processingfilerow.FieldID)
		for _, f := range fields {
			if !processingfilerow.ValidColumn(f) {
				return nil, &ValidationError{Name: f, err: fmt.Errorf("ent: invalid field %q for query", f)}
			}
			if f != processingfilerow.FieldID {
				_spec.Node.Columns = append(_spec.Node.Columns, f)
			}
		}
	}
	if ps := pfruo.mutation.predicates; len(ps) > 0 {
		_spec.Predicate = func(selector *sql.Selector) {
			for i := range ps {
				ps[i](selector)
			}
		}
	}
	if value, ok := pfruo.mutation.FileID(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeInt64,
			Value:  value,
			Column: processingfilerow.FieldFileID,
		})
	}
	if value, ok := pfruo.mutation.AddedFileID(); ok {
		_spec.Fields.Add = append(_spec.Fields.Add, &sqlgraph.FieldSpec{
			Type:   field.TypeInt64,
			Value:  value,
			Column: processingfilerow.FieldFileID,
		})
	}
	if value, ok := pfruo.mutation.RowIndex(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeInt32,
			Value:  value,
			Column: processingfilerow.FieldRowIndex,
		})
	}
	if value, ok := pfruo.mutation.AddedRowIndex(); ok {
		_spec.Fields.Add = append(_spec.Fields.Add, &sqlgraph.FieldSpec{
			Type:   field.TypeInt32,
			Value:  value,
			Column: processingfilerow.FieldRowIndex,
		})
	}
	if value, ok := pfruo.mutation.RowDataRaw(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  value,
			Column: processingfilerow.FieldRowDataRaw,
		})
	}
	if value, ok := pfruo.mutation.TaskIndex(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeInt32,
			Value:  value,
			Column: processingfilerow.FieldTaskIndex,
		})
	}
	if value, ok := pfruo.mutation.AddedTaskIndex(); ok {
		_spec.Fields.Add = append(_spec.Fields.Add, &sqlgraph.FieldSpec{
			Type:   field.TypeInt32,
			Value:  value,
			Column: processingfilerow.FieldTaskIndex,
		})
	}
	if value, ok := pfruo.mutation.TaskMapping(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  value,
			Column: processingfilerow.FieldTaskMapping,
		})
	}
	if value, ok := pfruo.mutation.TaskDependsOn(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  value,
			Column: processingfilerow.FieldTaskDependsOn,
		})
	}
	if value, ok := pfruo.mutation.TaskRequestRaw(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  value,
			Column: processingfilerow.FieldTaskRequestRaw,
		})
	}
	if value, ok := pfruo.mutation.TaskResponseRaw(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  value,
			Column: processingfilerow.FieldTaskResponseRaw,
		})
	}
	if value, ok := pfruo.mutation.Status(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeInt16,
			Value:  value,
			Column: processingfilerow.FieldStatus,
		})
	}
	if value, ok := pfruo.mutation.AddedStatus(); ok {
		_spec.Fields.Add = append(_spec.Fields.Add, &sqlgraph.FieldSpec{
			Type:   field.TypeInt16,
			Value:  value,
			Column: processingfilerow.FieldStatus,
		})
	}
	if value, ok := pfruo.mutation.ErrorDisplay(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  value,
			Column: processingfilerow.FieldErrorDisplay,
		})
	}
	if value, ok := pfruo.mutation.ExecutedTime(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeInt64,
			Value:  value,
			Column: processingfilerow.FieldExecutedTime,
		})
	}
	if value, ok := pfruo.mutation.AddedExecutedTime(); ok {
		_spec.Fields.Add = append(_spec.Fields.Add, &sqlgraph.FieldSpec{
			Type:   field.TypeInt64,
			Value:  value,
			Column: processingfilerow.FieldExecutedTime,
		})
	}
	if value, ok := pfruo.mutation.CreatedAt(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeTime,
			Value:  value,
			Column: processingfilerow.FieldCreatedAt,
		})
	}
	if value, ok := pfruo.mutation.UpdatedAt(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeTime,
			Value:  value,
			Column: processingfilerow.FieldUpdatedAt,
		})
	}
	_node = &ProcessingFileRow{config: pfruo.config}
	_spec.Assign = _node.assignValues
	_spec.ScanValues = _node.scanValues
	if err = sqlgraph.UpdateNode(ctx, pfruo.driver, _spec); err != nil {
		if _, ok := err.(*sqlgraph.NotFoundError); ok {
			err = &NotFoundError{processingfilerow.Label}
		} else if sqlgraph.IsConstraintError(err) {
			err = &ConstraintError{msg: err.Error(), wrap: err}
		}
		return nil, err
	}
	return _node, nil
}
