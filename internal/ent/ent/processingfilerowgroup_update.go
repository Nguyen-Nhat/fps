// Code generated by ent, DO NOT EDIT.

package ent

import (
	"context"
	"errors"
	"fmt"
	"time"

	"entgo.io/ent/dialect/sql"
	"entgo.io/ent/dialect/sql/sqlgraph"
	"entgo.io/ent/schema/field"
	"git.teko.vn/loyalty-system/loyalty-file-processing/internal/ent/ent/predicate"
	"git.teko.vn/loyalty-system/loyalty-file-processing/internal/ent/ent/processingfilerowgroup"
)

// ProcessingFileRowGroupUpdate is the builder for updating ProcessingFileRowGroup entities.
type ProcessingFileRowGroupUpdate struct {
	config
	hooks    []Hook
	mutation *ProcessingFileRowGroupMutation
}

// Where appends a list predicates to the ProcessingFileRowGroupUpdate builder.
func (pfrgu *ProcessingFileRowGroupUpdate) Where(ps ...predicate.ProcessingFileRowGroup) *ProcessingFileRowGroupUpdate {
	pfrgu.mutation.Where(ps...)
	return pfrgu
}

// SetFileID sets the "file_id" field.
func (pfrgu *ProcessingFileRowGroupUpdate) SetFileID(i int64) *ProcessingFileRowGroupUpdate {
	pfrgu.mutation.ResetFileID()
	pfrgu.mutation.SetFileID(i)
	return pfrgu
}

// AddFileID adds i to the "file_id" field.
func (pfrgu *ProcessingFileRowGroupUpdate) AddFileID(i int64) *ProcessingFileRowGroupUpdate {
	pfrgu.mutation.AddFileID(i)
	return pfrgu
}

// SetTaskIndex sets the "task_index" field.
func (pfrgu *ProcessingFileRowGroupUpdate) SetTaskIndex(i int32) *ProcessingFileRowGroupUpdate {
	pfrgu.mutation.ResetTaskIndex()
	pfrgu.mutation.SetTaskIndex(i)
	return pfrgu
}

// AddTaskIndex adds i to the "task_index" field.
func (pfrgu *ProcessingFileRowGroupUpdate) AddTaskIndex(i int32) *ProcessingFileRowGroupUpdate {
	pfrgu.mutation.AddTaskIndex(i)
	return pfrgu
}

// SetGroupByValue sets the "group_by_value" field.
func (pfrgu *ProcessingFileRowGroupUpdate) SetGroupByValue(s string) *ProcessingFileRowGroupUpdate {
	pfrgu.mutation.SetGroupByValue(s)
	return pfrgu
}

// SetTotalRows sets the "total_rows" field.
func (pfrgu *ProcessingFileRowGroupUpdate) SetTotalRows(i int32) *ProcessingFileRowGroupUpdate {
	pfrgu.mutation.ResetTotalRows()
	pfrgu.mutation.SetTotalRows(i)
	return pfrgu
}

// AddTotalRows adds i to the "total_rows" field.
func (pfrgu *ProcessingFileRowGroupUpdate) AddTotalRows(i int32) *ProcessingFileRowGroupUpdate {
	pfrgu.mutation.AddTotalRows(i)
	return pfrgu
}

// SetRowIndexList sets the "row_index_list" field.
func (pfrgu *ProcessingFileRowGroupUpdate) SetRowIndexList(s string) *ProcessingFileRowGroupUpdate {
	pfrgu.mutation.SetRowIndexList(s)
	return pfrgu
}

// SetGroupRequestCurl sets the "group_request_curl" field.
func (pfrgu *ProcessingFileRowGroupUpdate) SetGroupRequestCurl(s string) *ProcessingFileRowGroupUpdate {
	pfrgu.mutation.SetGroupRequestCurl(s)
	return pfrgu
}

// SetGroupResponseRaw sets the "group_response_raw" field.
func (pfrgu *ProcessingFileRowGroupUpdate) SetGroupResponseRaw(s string) *ProcessingFileRowGroupUpdate {
	pfrgu.mutation.SetGroupResponseRaw(s)
	return pfrgu
}

// SetStatus sets the "status" field.
func (pfrgu *ProcessingFileRowGroupUpdate) SetStatus(i int16) *ProcessingFileRowGroupUpdate {
	pfrgu.mutation.ResetStatus()
	pfrgu.mutation.SetStatus(i)
	return pfrgu
}

// AddStatus adds i to the "status" field.
func (pfrgu *ProcessingFileRowGroupUpdate) AddStatus(i int16) *ProcessingFileRowGroupUpdate {
	pfrgu.mutation.AddStatus(i)
	return pfrgu
}

// SetErrorDisplay sets the "error_display" field.
func (pfrgu *ProcessingFileRowGroupUpdate) SetErrorDisplay(s string) *ProcessingFileRowGroupUpdate {
	pfrgu.mutation.SetErrorDisplay(s)
	return pfrgu
}

// SetExecutedTime sets the "executed_time" field.
func (pfrgu *ProcessingFileRowGroupUpdate) SetExecutedTime(i int64) *ProcessingFileRowGroupUpdate {
	pfrgu.mutation.ResetExecutedTime()
	pfrgu.mutation.SetExecutedTime(i)
	return pfrgu
}

// AddExecutedTime adds i to the "executed_time" field.
func (pfrgu *ProcessingFileRowGroupUpdate) AddExecutedTime(i int64) *ProcessingFileRowGroupUpdate {
	pfrgu.mutation.AddExecutedTime(i)
	return pfrgu
}

// SetCreatedAt sets the "created_at" field.
func (pfrgu *ProcessingFileRowGroupUpdate) SetCreatedAt(t time.Time) *ProcessingFileRowGroupUpdate {
	pfrgu.mutation.SetCreatedAt(t)
	return pfrgu
}

// SetNillableCreatedAt sets the "created_at" field if the given value is not nil.
func (pfrgu *ProcessingFileRowGroupUpdate) SetNillableCreatedAt(t *time.Time) *ProcessingFileRowGroupUpdate {
	if t != nil {
		pfrgu.SetCreatedAt(*t)
	}
	return pfrgu
}

// SetUpdatedAt sets the "updated_at" field.
func (pfrgu *ProcessingFileRowGroupUpdate) SetUpdatedAt(t time.Time) *ProcessingFileRowGroupUpdate {
	pfrgu.mutation.SetUpdatedAt(t)
	return pfrgu
}

// Mutation returns the ProcessingFileRowGroupMutation object of the builder.
func (pfrgu *ProcessingFileRowGroupUpdate) Mutation() *ProcessingFileRowGroupMutation {
	return pfrgu.mutation
}

// Save executes the query and returns the number of nodes affected by the update operation.
func (pfrgu *ProcessingFileRowGroupUpdate) Save(ctx context.Context) (int, error) {
	var (
		err      error
		affected int
	)
	pfrgu.defaults()
	if len(pfrgu.hooks) == 0 {
		affected, err = pfrgu.sqlSave(ctx)
	} else {
		var mut Mutator = MutateFunc(func(ctx context.Context, m Mutation) (Value, error) {
			mutation, ok := m.(*ProcessingFileRowGroupMutation)
			if !ok {
				return nil, fmt.Errorf("unexpected mutation type %T", m)
			}
			pfrgu.mutation = mutation
			affected, err = pfrgu.sqlSave(ctx)
			mutation.done = true
			return affected, err
		})
		for i := len(pfrgu.hooks) - 1; i >= 0; i-- {
			if pfrgu.hooks[i] == nil {
				return 0, fmt.Errorf("ent: uninitialized hook (forgotten import ent/runtime?)")
			}
			mut = pfrgu.hooks[i](mut)
		}
		if _, err := mut.Mutate(ctx, pfrgu.mutation); err != nil {
			return 0, err
		}
	}
	return affected, err
}

// SaveX is like Save, but panics if an error occurs.
func (pfrgu *ProcessingFileRowGroupUpdate) SaveX(ctx context.Context) int {
	affected, err := pfrgu.Save(ctx)
	if err != nil {
		panic(err)
	}
	return affected
}

// Exec executes the query.
func (pfrgu *ProcessingFileRowGroupUpdate) Exec(ctx context.Context) error {
	_, err := pfrgu.Save(ctx)
	return err
}

// ExecX is like Exec, but panics if an error occurs.
func (pfrgu *ProcessingFileRowGroupUpdate) ExecX(ctx context.Context) {
	if err := pfrgu.Exec(ctx); err != nil {
		panic(err)
	}
}

// defaults sets the default values of the builder before save.
func (pfrgu *ProcessingFileRowGroupUpdate) defaults() {
	if _, ok := pfrgu.mutation.UpdatedAt(); !ok {
		v := processingfilerowgroup.UpdateDefaultUpdatedAt()
		pfrgu.mutation.SetUpdatedAt(v)
	}
}

func (pfrgu *ProcessingFileRowGroupUpdate) sqlSave(ctx context.Context) (n int, err error) {
	_spec := &sqlgraph.UpdateSpec{
		Node: &sqlgraph.NodeSpec{
			Table:   processingfilerowgroup.Table,
			Columns: processingfilerowgroup.Columns,
			ID: &sqlgraph.FieldSpec{
				Type:   field.TypeInt,
				Column: processingfilerowgroup.FieldID,
			},
		},
	}
	if ps := pfrgu.mutation.predicates; len(ps) > 0 {
		_spec.Predicate = func(selector *sql.Selector) {
			for i := range ps {
				ps[i](selector)
			}
		}
	}
	if value, ok := pfrgu.mutation.FileID(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeInt64,
			Value:  value,
			Column: processingfilerowgroup.FieldFileID,
		})
	}
	if value, ok := pfrgu.mutation.AddedFileID(); ok {
		_spec.Fields.Add = append(_spec.Fields.Add, &sqlgraph.FieldSpec{
			Type:   field.TypeInt64,
			Value:  value,
			Column: processingfilerowgroup.FieldFileID,
		})
	}
	if value, ok := pfrgu.mutation.TaskIndex(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeInt32,
			Value:  value,
			Column: processingfilerowgroup.FieldTaskIndex,
		})
	}
	if value, ok := pfrgu.mutation.AddedTaskIndex(); ok {
		_spec.Fields.Add = append(_spec.Fields.Add, &sqlgraph.FieldSpec{
			Type:   field.TypeInt32,
			Value:  value,
			Column: processingfilerowgroup.FieldTaskIndex,
		})
	}
	if value, ok := pfrgu.mutation.GroupByValue(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  value,
			Column: processingfilerowgroup.FieldGroupByValue,
		})
	}
	if value, ok := pfrgu.mutation.TotalRows(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeInt32,
			Value:  value,
			Column: processingfilerowgroup.FieldTotalRows,
		})
	}
	if value, ok := pfrgu.mutation.AddedTotalRows(); ok {
		_spec.Fields.Add = append(_spec.Fields.Add, &sqlgraph.FieldSpec{
			Type:   field.TypeInt32,
			Value:  value,
			Column: processingfilerowgroup.FieldTotalRows,
		})
	}
	if value, ok := pfrgu.mutation.RowIndexList(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  value,
			Column: processingfilerowgroup.FieldRowIndexList,
		})
	}
	if value, ok := pfrgu.mutation.GroupRequestCurl(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  value,
			Column: processingfilerowgroup.FieldGroupRequestCurl,
		})
	}
	if value, ok := pfrgu.mutation.GroupResponseRaw(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  value,
			Column: processingfilerowgroup.FieldGroupResponseRaw,
		})
	}
	if value, ok := pfrgu.mutation.Status(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeInt16,
			Value:  value,
			Column: processingfilerowgroup.FieldStatus,
		})
	}
	if value, ok := pfrgu.mutation.AddedStatus(); ok {
		_spec.Fields.Add = append(_spec.Fields.Add, &sqlgraph.FieldSpec{
			Type:   field.TypeInt16,
			Value:  value,
			Column: processingfilerowgroup.FieldStatus,
		})
	}
	if value, ok := pfrgu.mutation.ErrorDisplay(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  value,
			Column: processingfilerowgroup.FieldErrorDisplay,
		})
	}
	if value, ok := pfrgu.mutation.ExecutedTime(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeInt64,
			Value:  value,
			Column: processingfilerowgroup.FieldExecutedTime,
		})
	}
	if value, ok := pfrgu.mutation.AddedExecutedTime(); ok {
		_spec.Fields.Add = append(_spec.Fields.Add, &sqlgraph.FieldSpec{
			Type:   field.TypeInt64,
			Value:  value,
			Column: processingfilerowgroup.FieldExecutedTime,
		})
	}
	if value, ok := pfrgu.mutation.CreatedAt(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeTime,
			Value:  value,
			Column: processingfilerowgroup.FieldCreatedAt,
		})
	}
	if value, ok := pfrgu.mutation.UpdatedAt(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeTime,
			Value:  value,
			Column: processingfilerowgroup.FieldUpdatedAt,
		})
	}
	if n, err = sqlgraph.UpdateNodes(ctx, pfrgu.driver, _spec); err != nil {
		if _, ok := err.(*sqlgraph.NotFoundError); ok {
			err = &NotFoundError{processingfilerowgroup.Label}
		} else if sqlgraph.IsConstraintError(err) {
			err = &ConstraintError{msg: err.Error(), wrap: err}
		}
		return 0, err
	}
	return n, nil
}

// ProcessingFileRowGroupUpdateOne is the builder for updating a single ProcessingFileRowGroup entity.
type ProcessingFileRowGroupUpdateOne struct {
	config
	fields   []string
	hooks    []Hook
	mutation *ProcessingFileRowGroupMutation
}

// SetFileID sets the "file_id" field.
func (pfrguo *ProcessingFileRowGroupUpdateOne) SetFileID(i int64) *ProcessingFileRowGroupUpdateOne {
	pfrguo.mutation.ResetFileID()
	pfrguo.mutation.SetFileID(i)
	return pfrguo
}

// AddFileID adds i to the "file_id" field.
func (pfrguo *ProcessingFileRowGroupUpdateOne) AddFileID(i int64) *ProcessingFileRowGroupUpdateOne {
	pfrguo.mutation.AddFileID(i)
	return pfrguo
}

// SetTaskIndex sets the "task_index" field.
func (pfrguo *ProcessingFileRowGroupUpdateOne) SetTaskIndex(i int32) *ProcessingFileRowGroupUpdateOne {
	pfrguo.mutation.ResetTaskIndex()
	pfrguo.mutation.SetTaskIndex(i)
	return pfrguo
}

// AddTaskIndex adds i to the "task_index" field.
func (pfrguo *ProcessingFileRowGroupUpdateOne) AddTaskIndex(i int32) *ProcessingFileRowGroupUpdateOne {
	pfrguo.mutation.AddTaskIndex(i)
	return pfrguo
}

// SetGroupByValue sets the "group_by_value" field.
func (pfrguo *ProcessingFileRowGroupUpdateOne) SetGroupByValue(s string) *ProcessingFileRowGroupUpdateOne {
	pfrguo.mutation.SetGroupByValue(s)
	return pfrguo
}

// SetTotalRows sets the "total_rows" field.
func (pfrguo *ProcessingFileRowGroupUpdateOne) SetTotalRows(i int32) *ProcessingFileRowGroupUpdateOne {
	pfrguo.mutation.ResetTotalRows()
	pfrguo.mutation.SetTotalRows(i)
	return pfrguo
}

// AddTotalRows adds i to the "total_rows" field.
func (pfrguo *ProcessingFileRowGroupUpdateOne) AddTotalRows(i int32) *ProcessingFileRowGroupUpdateOne {
	pfrguo.mutation.AddTotalRows(i)
	return pfrguo
}

// SetRowIndexList sets the "row_index_list" field.
func (pfrguo *ProcessingFileRowGroupUpdateOne) SetRowIndexList(s string) *ProcessingFileRowGroupUpdateOne {
	pfrguo.mutation.SetRowIndexList(s)
	return pfrguo
}

// SetGroupRequestCurl sets the "group_request_curl" field.
func (pfrguo *ProcessingFileRowGroupUpdateOne) SetGroupRequestCurl(s string) *ProcessingFileRowGroupUpdateOne {
	pfrguo.mutation.SetGroupRequestCurl(s)
	return pfrguo
}

// SetGroupResponseRaw sets the "group_response_raw" field.
func (pfrguo *ProcessingFileRowGroupUpdateOne) SetGroupResponseRaw(s string) *ProcessingFileRowGroupUpdateOne {
	pfrguo.mutation.SetGroupResponseRaw(s)
	return pfrguo
}

// SetStatus sets the "status" field.
func (pfrguo *ProcessingFileRowGroupUpdateOne) SetStatus(i int16) *ProcessingFileRowGroupUpdateOne {
	pfrguo.mutation.ResetStatus()
	pfrguo.mutation.SetStatus(i)
	return pfrguo
}

// AddStatus adds i to the "status" field.
func (pfrguo *ProcessingFileRowGroupUpdateOne) AddStatus(i int16) *ProcessingFileRowGroupUpdateOne {
	pfrguo.mutation.AddStatus(i)
	return pfrguo
}

// SetErrorDisplay sets the "error_display" field.
func (pfrguo *ProcessingFileRowGroupUpdateOne) SetErrorDisplay(s string) *ProcessingFileRowGroupUpdateOne {
	pfrguo.mutation.SetErrorDisplay(s)
	return pfrguo
}

// SetExecutedTime sets the "executed_time" field.
func (pfrguo *ProcessingFileRowGroupUpdateOne) SetExecutedTime(i int64) *ProcessingFileRowGroupUpdateOne {
	pfrguo.mutation.ResetExecutedTime()
	pfrguo.mutation.SetExecutedTime(i)
	return pfrguo
}

// AddExecutedTime adds i to the "executed_time" field.
func (pfrguo *ProcessingFileRowGroupUpdateOne) AddExecutedTime(i int64) *ProcessingFileRowGroupUpdateOne {
	pfrguo.mutation.AddExecutedTime(i)
	return pfrguo
}

// SetCreatedAt sets the "created_at" field.
func (pfrguo *ProcessingFileRowGroupUpdateOne) SetCreatedAt(t time.Time) *ProcessingFileRowGroupUpdateOne {
	pfrguo.mutation.SetCreatedAt(t)
	return pfrguo
}

// SetNillableCreatedAt sets the "created_at" field if the given value is not nil.
func (pfrguo *ProcessingFileRowGroupUpdateOne) SetNillableCreatedAt(t *time.Time) *ProcessingFileRowGroupUpdateOne {
	if t != nil {
		pfrguo.SetCreatedAt(*t)
	}
	return pfrguo
}

// SetUpdatedAt sets the "updated_at" field.
func (pfrguo *ProcessingFileRowGroupUpdateOne) SetUpdatedAt(t time.Time) *ProcessingFileRowGroupUpdateOne {
	pfrguo.mutation.SetUpdatedAt(t)
	return pfrguo
}

// Mutation returns the ProcessingFileRowGroupMutation object of the builder.
func (pfrguo *ProcessingFileRowGroupUpdateOne) Mutation() *ProcessingFileRowGroupMutation {
	return pfrguo.mutation
}

// Select allows selecting one or more fields (columns) of the returned entity.
// The default is selecting all fields defined in the entity schema.
func (pfrguo *ProcessingFileRowGroupUpdateOne) Select(field string, fields ...string) *ProcessingFileRowGroupUpdateOne {
	pfrguo.fields = append([]string{field}, fields...)
	return pfrguo
}

// Save executes the query and returns the updated ProcessingFileRowGroup entity.
func (pfrguo *ProcessingFileRowGroupUpdateOne) Save(ctx context.Context) (*ProcessingFileRowGroup, error) {
	var (
		err  error
		node *ProcessingFileRowGroup
	)
	pfrguo.defaults()
	if len(pfrguo.hooks) == 0 {
		node, err = pfrguo.sqlSave(ctx)
	} else {
		var mut Mutator = MutateFunc(func(ctx context.Context, m Mutation) (Value, error) {
			mutation, ok := m.(*ProcessingFileRowGroupMutation)
			if !ok {
				return nil, fmt.Errorf("unexpected mutation type %T", m)
			}
			pfrguo.mutation = mutation
			node, err = pfrguo.sqlSave(ctx)
			mutation.done = true
			return node, err
		})
		for i := len(pfrguo.hooks) - 1; i >= 0; i-- {
			if pfrguo.hooks[i] == nil {
				return nil, fmt.Errorf("ent: uninitialized hook (forgotten import ent/runtime?)")
			}
			mut = pfrguo.hooks[i](mut)
		}
		v, err := mut.Mutate(ctx, pfrguo.mutation)
		if err != nil {
			return nil, err
		}
		nv, ok := v.(*ProcessingFileRowGroup)
		if !ok {
			return nil, fmt.Errorf("unexpected node type %T returned from ProcessingFileRowGroupMutation", v)
		}
		node = nv
	}
	return node, err
}

// SaveX is like Save, but panics if an error occurs.
func (pfrguo *ProcessingFileRowGroupUpdateOne) SaveX(ctx context.Context) *ProcessingFileRowGroup {
	node, err := pfrguo.Save(ctx)
	if err != nil {
		panic(err)
	}
	return node
}

// Exec executes the query on the entity.
func (pfrguo *ProcessingFileRowGroupUpdateOne) Exec(ctx context.Context) error {
	_, err := pfrguo.Save(ctx)
	return err
}

// ExecX is like Exec, but panics if an error occurs.
func (pfrguo *ProcessingFileRowGroupUpdateOne) ExecX(ctx context.Context) {
	if err := pfrguo.Exec(ctx); err != nil {
		panic(err)
	}
}

// defaults sets the default values of the builder before save.
func (pfrguo *ProcessingFileRowGroupUpdateOne) defaults() {
	if _, ok := pfrguo.mutation.UpdatedAt(); !ok {
		v := processingfilerowgroup.UpdateDefaultUpdatedAt()
		pfrguo.mutation.SetUpdatedAt(v)
	}
}

func (pfrguo *ProcessingFileRowGroupUpdateOne) sqlSave(ctx context.Context) (_node *ProcessingFileRowGroup, err error) {
	_spec := &sqlgraph.UpdateSpec{
		Node: &sqlgraph.NodeSpec{
			Table:   processingfilerowgroup.Table,
			Columns: processingfilerowgroup.Columns,
			ID: &sqlgraph.FieldSpec{
				Type:   field.TypeInt,
				Column: processingfilerowgroup.FieldID,
			},
		},
	}
	id, ok := pfrguo.mutation.ID()
	if !ok {
		return nil, &ValidationError{Name: "id", err: errors.New(`ent: missing "ProcessingFileRowGroup.id" for update`)}
	}
	_spec.Node.ID.Value = id
	if fields := pfrguo.fields; len(fields) > 0 {
		_spec.Node.Columns = make([]string, 0, len(fields))
		_spec.Node.Columns = append(_spec.Node.Columns, processingfilerowgroup.FieldID)
		for _, f := range fields {
			if !processingfilerowgroup.ValidColumn(f) {
				return nil, &ValidationError{Name: f, err: fmt.Errorf("ent: invalid field %q for query", f)}
			}
			if f != processingfilerowgroup.FieldID {
				_spec.Node.Columns = append(_spec.Node.Columns, f)
			}
		}
	}
	if ps := pfrguo.mutation.predicates; len(ps) > 0 {
		_spec.Predicate = func(selector *sql.Selector) {
			for i := range ps {
				ps[i](selector)
			}
		}
	}
	if value, ok := pfrguo.mutation.FileID(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeInt64,
			Value:  value,
			Column: processingfilerowgroup.FieldFileID,
		})
	}
	if value, ok := pfrguo.mutation.AddedFileID(); ok {
		_spec.Fields.Add = append(_spec.Fields.Add, &sqlgraph.FieldSpec{
			Type:   field.TypeInt64,
			Value:  value,
			Column: processingfilerowgroup.FieldFileID,
		})
	}
	if value, ok := pfrguo.mutation.TaskIndex(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeInt32,
			Value:  value,
			Column: processingfilerowgroup.FieldTaskIndex,
		})
	}
	if value, ok := pfrguo.mutation.AddedTaskIndex(); ok {
		_spec.Fields.Add = append(_spec.Fields.Add, &sqlgraph.FieldSpec{
			Type:   field.TypeInt32,
			Value:  value,
			Column: processingfilerowgroup.FieldTaskIndex,
		})
	}
	if value, ok := pfrguo.mutation.GroupByValue(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  value,
			Column: processingfilerowgroup.FieldGroupByValue,
		})
	}
	if value, ok := pfrguo.mutation.TotalRows(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeInt32,
			Value:  value,
			Column: processingfilerowgroup.FieldTotalRows,
		})
	}
	if value, ok := pfrguo.mutation.AddedTotalRows(); ok {
		_spec.Fields.Add = append(_spec.Fields.Add, &sqlgraph.FieldSpec{
			Type:   field.TypeInt32,
			Value:  value,
			Column: processingfilerowgroup.FieldTotalRows,
		})
	}
	if value, ok := pfrguo.mutation.RowIndexList(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  value,
			Column: processingfilerowgroup.FieldRowIndexList,
		})
	}
	if value, ok := pfrguo.mutation.GroupRequestCurl(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  value,
			Column: processingfilerowgroup.FieldGroupRequestCurl,
		})
	}
	if value, ok := pfrguo.mutation.GroupResponseRaw(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  value,
			Column: processingfilerowgroup.FieldGroupResponseRaw,
		})
	}
	if value, ok := pfrguo.mutation.Status(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeInt16,
			Value:  value,
			Column: processingfilerowgroup.FieldStatus,
		})
	}
	if value, ok := pfrguo.mutation.AddedStatus(); ok {
		_spec.Fields.Add = append(_spec.Fields.Add, &sqlgraph.FieldSpec{
			Type:   field.TypeInt16,
			Value:  value,
			Column: processingfilerowgroup.FieldStatus,
		})
	}
	if value, ok := pfrguo.mutation.ErrorDisplay(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  value,
			Column: processingfilerowgroup.FieldErrorDisplay,
		})
	}
	if value, ok := pfrguo.mutation.ExecutedTime(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeInt64,
			Value:  value,
			Column: processingfilerowgroup.FieldExecutedTime,
		})
	}
	if value, ok := pfrguo.mutation.AddedExecutedTime(); ok {
		_spec.Fields.Add = append(_spec.Fields.Add, &sqlgraph.FieldSpec{
			Type:   field.TypeInt64,
			Value:  value,
			Column: processingfilerowgroup.FieldExecutedTime,
		})
	}
	if value, ok := pfrguo.mutation.CreatedAt(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeTime,
			Value:  value,
			Column: processingfilerowgroup.FieldCreatedAt,
		})
	}
	if value, ok := pfrguo.mutation.UpdatedAt(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeTime,
			Value:  value,
			Column: processingfilerowgroup.FieldUpdatedAt,
		})
	}
	_node = &ProcessingFileRowGroup{config: pfrguo.config}
	_spec.Assign = _node.assignValues
	_spec.ScanValues = _node.scanValues
	if err = sqlgraph.UpdateNode(ctx, pfrguo.driver, _spec); err != nil {
		if _, ok := err.(*sqlgraph.NotFoundError); ok {
			err = &NotFoundError{processingfilerowgroup.Label}
		} else if sqlgraph.IsConstraintError(err) {
			err = &ConstraintError{msg: err.Error(), wrap: err}
		}
		return nil, err
	}
	return _node, nil
}
